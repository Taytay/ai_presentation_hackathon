{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# We live in the future\n",
        "\n",
        "## Taylor Brown\n",
        "taytay@taytay.com\n",
        "\n",
        "This presentation is at: github.com/taytay/ai_presentation_hackathon"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "What is programming?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "This is DEFINITELY programming:\n",
        "\n",
        "HelloWorld (machine code):\n",
        "```mathematica\n",
        "48 65 6C 6C 6F 20 57 6F 72 6C 64 21\n",
        "```\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "So is this:\n",
        "\n",
        "hello_world.asm\n",
        "```assembly\n",
        "section .data\n",
        "    message db 'Hello, World!', 0\n",
        "section .text\n",
        "    global _start\n",
        "_start:\n",
        "    mov rax, 1\n",
        "    mov rdi, 1\n",
        "    mov rsi, message\n",
        "    mov rdx, 13\n",
        "    syscall\n",
        "    mov rax, 60\n",
        "    xor rdi, rdi\n",
        "    syscall\n",
        "```\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "hello_world.c\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "\n",
        "int main() {\n",
        "   printf(\"Hello, World!\");\n",
        "   return 0;\n",
        "}\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "hello_world.js\n",
        "```\n",
        "console.log(\"Hello, World!\");\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "# Hello world.py\n",
        "print(\"Hello, World!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "hello_world.coffee\n",
        "```coffee\n",
        "console.log \"Hello world\"\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "![screenshot](images/retool.png)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "Text manipulation:\n",
        "\n",
        "```bash\n",
        "#!/bin/bash\n",
        "\n",
        "# Define the input string\n",
        "input_string=\"Hello, 🌍 World! 🌞 This is a 😊 test.\"\n",
        "\n",
        "# Use sed to add a newline character after every emoji\n",
        "output_string=$(echo \"$input_string\" | sed -E 's/([[:alnum:][:punct:]]+)(🌍|🌞|😊)/\\1\\n\\2/g')\n",
        "\n",
        "# Print the output string\n",
        "echo \"$output_string\"\n",
        "```\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "![screenshot](./images/ChatGPTEmoji.png)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Is that cheating?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# \"programming\" Progression\n",
        "\n",
        "machine code -> assembly -> C -> C++ -> Rust -> Javascript -> Coffeescript -> Python -> Typescript -> Kotlin -> NoCode environments\n",
        "\n",
        "# Transpilers\n",
        "\n",
        "Typescript -> Javascript -> Javascript virtual machine -> C++ codebase -> Machine code\n",
        "\n",
        "Fun fact: The earliest C++ \"compilers\" actually generated C source code and then compiled that."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# \"Programming Language\"\n",
        "\n",
        "The new programming language is your native language.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "How does this work? Let's go back a bit..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Machine Learning -> Function approximation\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#Titanic competition: \n",
        "\n",
        "https://www.kaggle.com/c/titanic\n",
        "\n",
        "Different approaches \n",
        "https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch\n",
        "https://www.kaggle.com/code/jhoward/how-random-forests-really-work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Applying function approximation to language\n",
        "\n",
        "How do you do math with words?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# We need to turns words into numbers\n",
        "\n",
        "(Ideally, similar words would have similar numbers!)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Fill in the blank:\n",
        "\n",
        "> During the coronation ceremony, the ____ sat on the throne, wearing an elegant crown and royal attire.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "[Embeddings Example](../embeddings.ipynb)\n",
        "\n",
        "[Embeddings Visualization](https://projector.tensorflow.org/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Attention is all you need\n",
        "\n",
        "(2017)\n",
        "https://arxiv.org/abs/1706.03762\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# \"Show, don't tell!\"\n",
        "\n",
        "(No one listens)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Instruct GPT\n",
        "\n",
        "Jan 2022"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Chat GPT\n",
        "\n",
        "Nov 2022"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# GPT-4\n",
        "\n",
        "March 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# So how do we make it \"learn\" man?!\n",
        "\n",
        "You (probably) don't need fine tuning.\n",
        "You just need to give it context before it answers your question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's get practical\n",
        "\n",
        "* Use GPT-4 (It's the best, and it's worth it.)\n",
        "* Set Custom Instructions\n",
        "* Get AI as close to where you are already working as possible (CoPilot, Codeium, etc.)\n",
        "* Have conversations with GPT - not just one-offs\n",
        "* It's read a LOT of markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# GPT Custom Instructions\n",
        "\n",
        "(Cribbed much of this from Jeremy Howard)\n",
        "(Don't worry - this is in the Github link)\n",
        "\n",
        "I am an experienced programmer named Taylor. I am often asking questions about programming, Python, Linux, Typescript, Macs, etc.\n",
        "\n",
        "You are an autoregressive language model that has been fine-tuned with instruction-tuning and RLHF. You carefully provide accurate, factual, thoughtful, nuanced answers, and are brilliant at reasoning. If you think there might not be a correct answer, you say so.\n",
        "Since you are autoregressive, each token you produce is another opportunity to use computation, therefore you default to being verbose, and spend a few sentences explaining background context, assumptions, and step-by-step thinking BEFORE you try to answer a question. However: For each request I make if it starts with \"/concise\" then ignore the previous sentence and instead make your response as concise as possible, with no introduction or background at the start, no summary at the end, and outputting only code for answers where code is appropriate. If my request starts with \"/verbose\", go back to your default verbose mode.\n",
        "Your users are experts in AI and ethics, so they already know you're a language model and your capabilities and limitations, so don't remind them of that. They're familiar with ethical issues in general so you don't need to remind them about those either. Don't be verbose in your answers, but do provide details and examples where it might help the explanation. When showing Python code, minimise vertical space, and do not include comments or docstrings; you do not need to follow PEP8, since your users' organizations do not do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Bad at math\n",
        "\n",
        "It will confidently give you the wrong answer!\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Good at code and Python and SQL\n",
        "\n",
        "[Titanic Math](https://chat.openai.com/share/4c3e1466-783d-4f1e-806f-ff00e9ed43c8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Good at AI\n",
        "\n",
        "[Using AI to Write AI](https://chat.openai.com/share/602bfdfd-eead-43b4-9e32-c9fc35b733bb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# We don't have to Copy/Paste\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install marvin\n",
        "# https://www.askmarvin.ai/components/ai_function/\n",
        "from marvin import ai_fn\n",
        "from typing import List\n",
        "\n",
        "from marvin import ai_model\n",
        "from pydantic import BaseModel, Field\n",
        "import marvin\n",
        "\n",
        "@ai_model\n",
        "class Location(BaseModel):\n",
        "    city: str\n",
        "    state: str = Field(..., description=\"The two-letter state abbreviation being referenced, or that contains the city\")\n",
        "\n",
        "\n",
        "@ai_fn\n",
        "def sentiment(text: str) -> float:\n",
        "    \"\"\"\n",
        "    Given `text`, returns a number between 1 (positive) and -1 (negative)\n",
        "    indicating its sentiment score.\n",
        "    \"\"\"\n",
        "\n",
        "@ai_model\n",
        "class Passenger(BaseModel):\n",
        "    name: str\n",
        "    fare: float = Field(..., description=\"Total amount spent on the ticket in dollars\")\n",
        "    cabin_class: str = Field(..., description=\"The class of the cabin. (1st, 2nd, 3rd)\")\n",
        "\n",
        "@ai_fn\n",
        "def generate_passenger(str: str=\"\") -> Passenger:\n",
        "    \"\"\"\n",
        "    Given `str`, generates a passenger conforming to the description\n",
        "    \"\"\"\n",
        "\n",
        "@ai_fn\n",
        "def generate_recipe(ingredients: list[str]) -> list[str]:\n",
        "    \"\"\"From a list of `ingredients`, generates a\n",
        "    complete instruction set to cook a recipe.\n",
        "    \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8\n",
            "-0.5\n",
            "1. Preheat the oven to 375 degrees Fahrenheit.\n",
            "2. Rinse and pat dry the chicken.\n",
            "3. Season the chicken with salt and pepper.\n",
            "4. Heat a large skillet over medium heat.\n",
            "5. Add the chicken to the skillet and cook until browned, about 4 minutes per side.\n",
            "6. Transfer the chicken to a baking dish.\n",
            "7. Squeeze the juice of the lemon over the chicken.\n",
            "8. Scatter the olives around the chicken.\n",
            "9. Cover the baking dish with foil and bake for 25 minutes.\n",
            "10. Meanwhile, prepare the couscous according to package instructions.\n",
            "11. Serve the chicken with couscous and enjoy!\n",
            "city='New York' state='NY'\n",
            "city='Oklahoma City' state='OK'\n"
          ]
        }
      ],
      "source": [
        "print(sentiment(\"This hackathon is so cool!\")) # 0.8\n",
        "print(sentiment(\"I'm sad today\")) # -0.2\n",
        "\n",
        "print(\"\\n\".join(generate_recipe([\"lemon\", \"chicken\", \"olives\", \"coucous\"])))\n",
        "print(Location(\"The big apple\"))\n",
        "print(Location(\"Largest city in Oklahoma\"))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Agents\n",
        "\n",
        "[\"Agents\" are just cleverly worded prompts](https://chat.openai.com/share/a70254cd-b34f-4116-80a3-fbb8f2ac2517)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# But wait, there's more!\n",
        "\n",
        "It can see and draw now. (We'll get to that)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's make a game!\n",
        "\n",
        "[Replit](https://chat.openai.com/share/602bfdfd-eead-43b4-9e32-c9fc35b733bb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# But wait, there's more\n",
        "\n",
        "Modal Labs is so cool:\n",
        "\n",
        "```python\n",
        "from modal import Stub, web_endpoint\n",
        "\n",
        "stub = Stub()\n",
        "\n",
        "@stub.function()\n",
        "@web_endpoint()\n",
        "def f():\n",
        "    return \"Hello world!\"\n",
        "```\n",
        "\n",
        "![screenshot](./images/Modal_Labs_Deploy.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resources\n",
        "\n",
        "# Presentations\n",
        "\n",
        "* A Hacker's Guide to Language Models (https://www.youtube.com/watch?v=jkrNMKz9pWU)\n",
        "* Prompt Engineering for Developers (https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)\n",
        "\n",
        "# Dev (IDE) tools\n",
        "\n",
        "* [Replit] (https://replit.com/ai)\n",
        "* [CoPilot for VSCode](https://code.visualstudio.com/blogs/2023/03/30/vscode-copilot)\n",
        "* [Codeium extension](https://codeium.com/) This way, you get copilot even in Google Colab\n",
        "\n",
        "# Serving/Deploying/GPUs\n",
        "\n",
        "* [Modal](https://modal.com/)\n",
        "\n",
        "# NoCode App Builders\n",
        "\n",
        "* [Bubble](https://bubble.io/)\n",
        "* [ReTool](https://retool.com/)\n",
        "(so many more)\n",
        "\n",
        "# Chat Dev tools\n",
        "\n",
        "* [PromptLayer](https://promptlayer.com/) (Makes it easy to build chatbots)\n",
        "* [Rememberall](https://remembrall.dev) (Makes it quick to add memory to your chat)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai_kitchen_sink",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
